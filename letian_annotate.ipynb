{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5b3a5ff-2ce4-411a-928b-e5c2b7a98480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d6508c-f974-45a1-81fb-334c92d0bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/data'\n",
    "output_file_sq= 'valid/annotations.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a3a4e8-9e50-4981-be9f-fad623a6a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:05<00:00, 14.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# find the largest light spot in image, write to a jsonl file\n",
    "def find_light_region(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        return None, None\n",
    "    _, thresh = cv2.threshold(image, 200, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) == 0:\n",
    "        return None, None\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    center_x = x + w / 2\n",
    "    center_y = y + h / 2\n",
    "    return (x, y, x + w, y + h), (center_x, center_y)\n",
    "\n",
    "def convert_to_jsonl(data_dir, output_file):\n",
    "    jsonl_data = []\n",
    "    for image_file in tqdm(os.listdir(data_dir)):\n",
    "        if image_file.endswith('.jpg'):\n",
    "            image_path = os.path.join(data_dir, image_file)\n",
    "            bbox, center = find_light_region(image_path)\n",
    "            if bbox and center:\n",
    "                x, y, x2, y2 = bbox\n",
    "                suffix = f\"light area<loc_{x}><loc_{y}><loc_{x2}><loc_{y2}>\"\n",
    "                data = {\n",
    "                    \"image\": image_file,\n",
    "                    \"prefix\": \"<OD>\",\n",
    "                    \"suffix\": suffix\n",
    "                }\n",
    "                jsonl_data.append(data)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in jsonl_data:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "convert_to_jsonl(data_dir, output_file_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8955e617-2dab-4fec-a244-876ac04d63e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the annotation to xml files\n",
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_voc_xml(annotation, img_path, output_dir):\n",
    "    folder = os.path.basename(os.path.dirname(img_path))\n",
    "    filename = os.path.basename(img_path)\n",
    "    img = Image.open(img_path)\n",
    "    width, height = img.size\n",
    "\n",
    "    annotation_xml = ET.Element(\"annotation\")\n",
    "    \n",
    "    folder_xml = ET.SubElement(annotation_xml, \"folder\")\n",
    "    folder_xml.text = folder\n",
    "    \n",
    "    filename_xml = ET.SubElement(annotation_xml, \"filename\")\n",
    "    filename_xml.text = filename\n",
    "    \n",
    "    path_xml = ET.SubElement(annotation_xml, \"path\")\n",
    "    path_xml.text = img_path\n",
    "    \n",
    "    source_xml = ET.SubElement(annotation_xml, \"source\")\n",
    "    database_xml = ET.SubElement(source_xml, \"database\")\n",
    "    database_xml.text = \"Unknown\"\n",
    "    \n",
    "    size_xml = ET.SubElement(annotation_xml, \"size\")\n",
    "    width_xml = ET.SubElement(size_xml, \"width\")\n",
    "    width_xml.text = str(width)\n",
    "    height_xml = ET.SubElement(size_xml, \"height\")\n",
    "    height_xml.text = str(height)\n",
    "    depth_xml = ET.SubElement(size_xml, \"depth\")\n",
    "    depth_xml.text = \"3\"\n",
    "    \n",
    "    segmented_xml = ET.SubElement(annotation_xml, \"segmented\")\n",
    "    segmented_xml.text = \"0\"\n",
    "    \n",
    "    obj_xml = ET.SubElement(annotation_xml, \"object\")\n",
    "    name_xml = ET.SubElement(obj_xml, \"name\")\n",
    "    name_xml.text = \"light_region\"\n",
    "    pose_xml = ET.SubElement(obj_xml, \"pose\")\n",
    "    pose_xml.text = \"Unspecified\"\n",
    "    truncated_xml = ET.SubElement(obj_xml, \"truncated\")\n",
    "    truncated_xml.text = \"0\"\n",
    "    difficult_xml = ET.SubElement(obj_xml, \"difficult\")\n",
    "    difficult_xml.text = \"0\"\n",
    "    \n",
    "    bndbox_xml = ET.SubElement(obj_xml, \"bndbox\")\n",
    "    xmin_xml = ET.SubElement(bndbox_xml, \"xmin\")\n",
    "    xmin_xml.text = str(annotation[0])\n",
    "    ymin_xml = ET.SubElement(bndbox_xml, \"ymin\")\n",
    "    ymin_xml.text = str(annotation[1])\n",
    "    xmax_xml = ET.SubElement(bndbox_xml, \"xmax\")\n",
    "    xmax_xml.text = str(annotation[2])\n",
    "    ymax_xml = ET.SubElement(bndbox_xml, \"ymax\")\n",
    "    ymax_xml.text = str(annotation[3])\n",
    "    \n",
    "    # make XML\n",
    "    xml_str = minidom.parseString(ET.tostring(annotation_xml)).toprettyxml(indent=\"   \")\n",
    "    xml_path = os.path.join(output_dir, filename.replace('.jpg', '.xml'))\n",
    "    with open(xml_path, \"w\") as f:\n",
    "        f.write(xml_str)\n",
    "\n",
    "# read jsonl\n",
    "jsonl_file = '/path/to/your/annotations.jsonl'\n",
    "annotations = []\n",
    "with open(jsonl_file, 'r') as f:\n",
    "    for line in f:\n",
    "        annotations.append(json.loads(line))\n",
    "\n",
    "\n",
    "data_dir = '/path/to/your/cryoEM/images'\n",
    "output_dir = '/path/to/output/xml_annotations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "#  Pascal VOC format XML \n",
    "for annotation in tqdm(annotations):\n",
    "    image_file = annotation['image']\n",
    "    suffix = annotation['suffix']\n",
    "    coords = suffix.split('<loc_')[1:]\n",
    "    coords = [int(c.split('>')[0]) for c in coords]\n",
    "    x, y, x2, y2 = coords\n",
    "    \n",
    "    image_path = os.path.join(data_dir, image_file)\n",
    "    create_voc_xml((x, y, x2, y2), image_path, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3644ad-7e7c-4d18-9fb4-d1ea4f30f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now adjust the box manually with  LabelImg if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2aada8-d05d-4084-9ae2-2345c9105b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fixing bad boxes, convert back to jsonl for training\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def parse_voc_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    filename = root.find('filename').text\n",
    "    bbox = root.find('object').find('bndbox')\n",
    "    x = int(bbox.find('xmin').text)\n",
    "    y = int(bbox.find('ymin').text)\n",
    "    x2 = int(bbox.find('xmax').text)\n",
    "    y2 = int(bbox.find('ymax').text)\n",
    "    suffix = f\"2D<loc_{x}><loc_{y}><loc_{x2}><loc_{y2}>\"\n",
    "    return {\n",
    "        \"image\": filename,\n",
    "        \"prefix\": \"<OD>\",\n",
    "        \"suffix\": suffix\n",
    "    }\n",
    "\n",
    "def convert_xml_to_jsonl(xml_dir, output_file):\n",
    "    jsonl_data = []\n",
    "    for xml_file in tqdm(os.listdir(xml_dir)):\n",
    "        if xml_file.endswith('.xml'):\n",
    "            xml_path = os.path.join(xml_dir, xml_file)\n",
    "            data = parse_voc_xml(xml_path)\n",
    "            jsonl_data.append(data)\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for entry in jsonl_data:\n",
    "            json.dump(entry, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "xml_dir = '/path/to/modified/xml_annotations'\n",
    "jsonl_output_file = '/path/to/modified/annotations.jsonl'\n",
    "convert_xml_to_jsonl(xml_dir, jsonl_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce9b4fb-beee-45e3-ac47-369ca06321ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the jsonl file above and write to a new jsonl file\n",
    "def normalize_coordinates(bbox, original_size, target_size=(1000, 1000)):\n",
    "    original_width, original_height = original_size\n",
    "    target_width, target_height = target_size\n",
    "    \n",
    "    x1, y1, x2, y2 = bbox\n",
    "    \n",
    "    x1_norm = (x1 / original_width) * target_width\n",
    "    y1_norm = (y1 / original_height) * target_height\n",
    "    x2_norm = (x2 / original_width) * target_width\n",
    "    y2_norm = (y2 / original_height) * target_height\n",
    "    \n",
    "    return [x1_norm, y1_norm, x2_norm, y2_norm]\n",
    "\n",
    "\n",
    "\n",
    "def normalize_annotations(jsonl_file_path, output_file_path,image_dir):\n",
    "    normalized_entries = []\n",
    "\n",
    "    with open(jsonl_file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            image_path = os.path.join(image_dir, data['image'])\n",
    "            image = Image.open(image_path)\n",
    "            original_size = image.size\n",
    "            #print(original_size)\n",
    "            suffix = data['suffix']\n",
    "            #print(suffix)\n",
    "\n",
    "            coords=suffix.split('<loc_')\n",
    "            coords=coords[1:]\n",
    "            coords = [int(s[:-1]) for s in coords]\n",
    "            print(coords)\n",
    "            bbox = normalize_coordinates(coords, original_size)\n",
    "            \n",
    "            new_suffix = f\"light area<loc_{int(bbox[0])}><loc_{int(bbox[1])}><loc_{int(bbox[2])}><loc_{int(bbox[3])}>\"\n",
    "            normalized_entry = {\n",
    "                \"image\": data[\"image\"],\n",
    "                \"prefix\": data[\"prefix\"],\n",
    "                \"suffix\": new_suffix\n",
    "            }\n",
    "            print(normalized_entry)\n",
    "            normalized_entries.append(normalized_entry)\n",
    "    \n",
    "    with open(output_file_path, 'w') as outfile:\n",
    "        for entry in normalized_entries:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "#valid_image_dir=\"/mnt/NCEP-CryoEM/active/merkaa/florence/20210114/\"\n",
    "#normalize_annotations('valid/annotations.jsonl', 'valid/normalized_annotations.jsonl',valid_image_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.12(ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
